{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of data related to trips from and to Paris with shared vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libs imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting directly to the csv file on data.gouv.fr (and testing the file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"journey_id\";\"trip_id\";\"journey_start_datetime\";\"journey_start_date\";\"journey_start_time\";\"journey_start_lon\";\"journey_start_lat\";\"journey_start_insee\";\"journey_start_department\";\"journey_start_town\";\"journey_start_towngroup\";\"journey_start_country\";\"journey_end_datetime\";\"journey_end_date\";\"journey_end_time\";\"journey_end_lon\";\"journey_end_lat\";\"journey_end_insee\";\"journey_end_department\";\"journey_end_town\";\"journey_end_towngroup\";\"journey_end_country\";\"passenger_seats\";\"operator_class\";\"journey_distance\";\"journey_duration\";\"has_incentive\"\n",
      "\"21223205\";\"7ebf6533-a58c-4367-9a11-574ce726e5f5\";\"2024-01-01T00:00:00+01:00\";\"2024-01-01\";\"00:00:00\";\"2.351\";\"48.810\";\"94043\";\"94\";\"Le Kremlin-BicÃªtre\";\"MÃ©tropole du Grand Paris\";\"France\";\"2024-01-01T00:30:00+01:00\";\"2024-01-01\";\"00:30:00\";\"2.372\";\"48.953\";\"93072\";\"93\";\"Stains\";\"MÃ©tropole du Grand Paris\";\"France\";\"1\";\"C\";\"23398\";\"29\";\"OUI\"\n",
      "\"21213421\";\"970d5c9b-9717-4f5f-8418-7dd00a0425ee\";\"2024-01-01T00:00:00+01:00\";\"2024-01-01\";\"00:00:00\";\"2.198\n"
     ]
    }
   ],
   "source": [
    "# test url\n",
    "url_2401 = 'https://static.data.gouv.fr/resources/trajets-realises-en-covoiturage-registre-de-preuve-de-covoiturage/20240208-001343/2024-01.csv'\n",
    "\n",
    "# raw reading of the file to see what separators are used in the file\n",
    "r = requests.get(url_2401)\n",
    "print(r.text[:1000]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 896309 entries, 0 to 941039\n",
      "Data columns (total 27 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   journey_id                896309 non-null  int64  \n",
      " 1   trip_id                   896309 non-null  object \n",
      " 2   journey_start_datetime    896309 non-null  object \n",
      " 3   journey_start_date        896309 non-null  object \n",
      " 4   journey_start_time        896309 non-null  object \n",
      " 5   journey_start_lon         896309 non-null  float64\n",
      " 6   journey_start_lat         896309 non-null  float64\n",
      " 7   journey_start_insee       896309 non-null  object \n",
      " 8   journey_start_department  896309 non-null  object \n",
      " 9   journey_start_town        896309 non-null  object \n",
      " 10  journey_start_towngroup   896309 non-null  object \n",
      " 11  journey_start_country     896309 non-null  object \n",
      " 12  journey_end_datetime      896309 non-null  object \n",
      " 13  journey_end_date          896309 non-null  object \n",
      " 14  journey_end_time          896309 non-null  object \n",
      " 15  journey_end_lon           896309 non-null  float64\n",
      " 16  journey_end_lat           896309 non-null  float64\n",
      " 17  journey_end_insee         896309 non-null  object \n",
      " 18  journey_end_department    896309 non-null  object \n",
      " 19  journey_end_town          896309 non-null  object \n",
      " 20  journey_end_towngroup     896309 non-null  object \n",
      " 21  journey_end_country       896309 non-null  object \n",
      " 22  passenger_seats           896309 non-null  int64  \n",
      " 23  operator_class            896309 non-null  object \n",
      " 24  journey_distance          896309 non-null  int64  \n",
      " 25  journey_duration          896309 non-null  int64  \n",
      " 26  has_incentive             896309 non-null  object \n",
      "dtypes: float64(4), int64(4), object(19)\n",
      "memory usage: 191.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# reading the csv file and checking some details about it\n",
    "df = pd.read_csv(url_2401, sep=\";\", low_memory=False)\n",
    "df = df.dropna(subset=[\"journey_id\", \"journey_start_date\", \"journey_start_department\", \"journey_start_town\", \"journey_end_department\", \"journey_end_town\", \"passenger_seats\", \"journey_distance\", \"journey_duration\"])\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only keeping useful data and columns (Paris-related trips, journey distance, number of passengers, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19167 entries, 60 to 941029\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   journey_id                19167 non-null  int64 \n",
      " 1   journey_start_date        19167 non-null  object\n",
      " 2   journey_start_department  19167 non-null  int64 \n",
      " 3   journey_start_town        19167 non-null  object\n",
      " 4   journey_end_department    19167 non-null  int64 \n",
      " 5   journey_end_town          19167 non-null  object\n",
      " 6   passenger_seats           19167 non-null  int64 \n",
      " 7   journey_distance          19167 non-null  int64 \n",
      " 8   journey_duration          19167 non-null  int64 \n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df[(df[\"journey_start_department\"] == \"75\") | (df[\"journey_end_department\"] == \"75\")] \n",
    "df = df[[\"journey_id\", \"journey_start_date\", \"journey_start_department\", \"journey_start_town\", \"journey_end_department\", \"journey_end_town\", \"passenger_seats\", \"journey_distance\", \"journey_duration\"]]\n",
    "df = df[df[\"journey_duration\"] >= 10]\n",
    "df[\"journey_start_department\"] = df[\"journey_start_department\"].astype(int)\n",
    "df[\"journey_end_department\"] = df[\"journey_end_department\"].astype(int)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going for the full set of csv files from 2019 to 2024, fusing them into a single csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the json containing the manually-scraped urls pointing to all needed csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"registre-preuve-covoiturage_Data_Gouv_urls.json\", \"r\") as f:\n",
    "    urls = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping through csv for all available years and months "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2019-02...\n",
      "Processing 2019-03...\n",
      "Processing 2019-04...\n",
      "Processing 2019-05...\n",
      "Processing 2019-06...\n",
      "Processing 2019-07...\n",
      "Processing 2019-08...\n",
      "Processing 2019-09...\n",
      "Processing 2019-10...\n",
      "Processing 2019-11...\n",
      "Processing 2019-12...\n",
      "Processing 2020-01...\n",
      "Processing 2020-02...\n",
      "Processing 2020-03...\n",
      "Processing 2020-04...\n",
      "Processing 2020-05...\n",
      "Processing 2020-06...\n",
      "Processing 2020-07...\n",
      "Processing 2020-08...\n",
      "Processing 2020-09...\n",
      "Processing 2020-10...\n",
      "Processing 2020-11...\n",
      "Processing 2020-12...\n",
      "Processing 2021-01...\n",
      "Processing 2021-02...\n",
      "Processing 2021-03...\n",
      "Processing 2021-04...\n",
      "Processing 2021-05...\n",
      "Processing 2021-06...\n",
      "Processing 2021-07...\n",
      "Processing 2021-08...\n",
      "Processing 2021-09...\n",
      "Processing 2021-10...\n",
      "Processing 2021-11...\n",
      "Processing 2021-12...\n",
      "Processing 2022-01...\n",
      "Processing 2022-02...\n",
      "Processing 2022-03...\n",
      "Processing 2022-04...\n",
      "Processing 2022-05...\n",
      "Processing 2022-06...\n",
      "Processing 2022-07...\n",
      "Processing 2022-08...\n",
      "Processing 2022-09...\n",
      "Processing 2022-10...\n",
      "Processing 2022-11...\n",
      "Processing 2022-12...\n",
      "Processing 2023-01...\n",
      "Processing 2023-02...\n",
      "Processing 2023-03...\n",
      "Processing 2023-04...\n",
      "Processing 2023-05...\n",
      "Processing 2023-06...\n",
      "Processing 2023-07...\n",
      "Processing 2023-08...\n",
      "Processing 2023-09...\n",
      "Processing 2023-10...\n",
      "Processing 2023-11...\n",
      "Processing 2023-12...\n",
      "Processing 2024-01...\n",
      "Processing 2024-02...\n",
      "Processing 2024-03...\n",
      "Processing 2024-04...\n",
      "Processing 2024-05...\n",
      "Processing 2024-06...\n",
      "Processing 2024-07...\n",
      "Processing 2024-08...\n",
      "Processing 2024-09...\n",
      "Processing 2024-10...\n",
      "Processing 2024-11...\n",
      "Processing 2024-12...\n"
     ]
    }
   ],
   "source": [
    "# List to accumulate dataframes\n",
    "dfs = []\n",
    "\n",
    "for key in urls:\n",
    "    url = urls[key]\n",
    "    print(f\"Processing {key}...\")\n",
    "    df = pd.read_csv(url, sep=\";\", low_memory=False)\n",
    "    # Filtering Paris\n",
    "    df = df[(df[\"journey_start_department\"] == \"75\") | (df[\"journey_end_department\"] == \"75\")] \n",
    "    # Filtering columns\n",
    "    df = df[[\"journey_id\", \"journey_start_date\", \"journey_start_department\", \"journey_start_town\", \"journey_end_department\", \"journey_end_town\", \"passenger_seats\", \"journey_distance\", \"journey_duration\"]]\n",
    "    #droping NA rows\n",
    "    df = df.dropna()\n",
    "    # Filtering unrelevant trips (duration < 5 min) \n",
    "    df = df[df[\"journey_duration\"] >= 5]\n",
    "    # Changing some types\n",
    "    df[\"journey_start_department\"] = df[\"journey_start_department\"].astype(int)\n",
    "    df[\"journey_end_department\"] = df[\"journey_end_department\"].astype(int)\n",
    "    # Adding to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concat all DataFrames in one go\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   journey_id journey_start_date  journey_start_department  \\\n",
      "0     7226722         2022-06-01                        75   \n",
      "1     7243957         2022-06-01                        75   \n",
      "2     7226731         2022-06-01                        75   \n",
      "3     7230744         2022-06-01                        91   \n",
      "4     7289879         2022-06-01                        91   \n",
      "\n",
      "     journey_start_town  journey_end_department journey_end_town  \\\n",
      "0                 Paris                      77         Jossigny   \n",
      "1                 Paris                      77         Jossigny   \n",
      "2                 Paris                      75            Paris   \n",
      "3    Évry-Courcouronnes                      75            Paris   \n",
      "4  Le Coudray-Montceaux                      75            Paris   \n",
      "\n",
      "   passenger_seats  journey_distance  journey_duration  \n",
      "0                1             25475                36  \n",
      "1                1             25780                38  \n",
      "2                1              3113                14  \n",
      "3                1             34689                52  \n",
      "4                1             37119                30  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 606480 entries, 0 to 606479\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   journey_id                606480 non-null  int64 \n",
      " 1   journey_start_date        606480 non-null  object\n",
      " 2   journey_start_department  606480 non-null  int64 \n",
      " 3   journey_start_town        606480 non-null  object\n",
      " 4   journey_end_department    606480 non-null  int64 \n",
      " 5   journey_end_town          606480 non-null  object\n",
      " 6   passenger_seats           606480 non-null  int64 \n",
      " 7   journey_distance          606480 non-null  int64 \n",
      " 8   journey_duration          606480 non-null  int64 \n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 41.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_final.head())\n",
    "print(df_final.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"registre-preuve-covoiturage_Data_Gouv.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
